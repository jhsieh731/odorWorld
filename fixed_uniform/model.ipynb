{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SETTINGS\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "\n",
    "# LEARNING RATE SETTINGS\n",
    "BASE_LR = 0.001\n",
    "DECAY_WEIGHT = 0.1 # factor by which the learning rate is reduced.\n",
    "EPOCH_DECAY = 30 # number of epochs after which the learning rate is decayed exponentially by DECAY_WEIGHT.\n",
    "\n",
    "\n",
    "# DATASET INFO\n",
    "NUM_CLASSES = 500 # set the number of classes in your dataset\n",
    "\n",
    "\n",
    "# DATALOADER PROPERTIES\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# GPU SETTINGS\n",
    "CUDA_DEVICE = 0 # Enter device ID of your gpu if you want to run on gpu. Otherwise neglect.\n",
    "GPU_MODE = 0 # set to 1 if want to run on gpu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark: 6m45s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_class import FixedUniformDataset\n",
    "\n",
    "dsets = {}\n",
    "# for split in ['train', 'test']:\n",
    "for split in ['train']:\n",
    "    dsets[split] = FixedUniformDataset(split+'ing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {}\n",
    "# for split in ['train', 'test']:\n",
    "for split in ['train']:\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelyn/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/profiler.py:179: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
      "STAGE:2024-04-02 12:33:31 24432:20534365 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2024-04-02 12:33:31 24432:20534365 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2024-04-02 12:33:31 24432:20534365 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'getitem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile, record_function, ProfilerActivity\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profile(activities\u001b[38;5;241m=\u001b[39m[ProfilerActivity\u001b[38;5;241m.\u001b[39mCPU, ProfilerActivity\u001b[38;5;241m.\u001b[39mCUDA], profile_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, record_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mdset_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitem\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'getitem'"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
    "\n",
    "    # testing\n",
    "    for data in dset_loaders['train']:\n",
    "        inputs, labels = data\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500])\n",
      "tensor([346, 102, 357, 345, 344, 355,  72, 192,  11, 412, 448, 477, 261, 495,\n",
      "        452, 108, 485, 246, 266, 118, 449, 293, 488, 104, 174, 309,  88, 212,\n",
      "         68, 362,  39,  79])\n",
      "tensor([346, 102, 357, 345, 344, 359,  74, 192,  17, 424, 359, 494, 431, 442,\n",
      "        359, 108, 485, 246, 266, 118, 359, 293, 489, 104, 174, 309,  88, 359,\n",
      "         74, 362,  42,  74])\n",
      "5.6702728271484375\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = Variable(inputs), Variable(labels)\n",
    "outputs = model_ft(inputs)\n",
    "print(outputs[0].shape)\n",
    "print(labels)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(outputs, labels)\n",
    "print(preds)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE_TENSORBOARD = False\n",
    "use_gpu = GPU_MODE\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(CUDA_DEVICE)\n",
    "\n",
    "# def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=100):\n",
    "#     since = time.time()\n",
    "\n",
    "#     best_model = model\n",
    "#     best_acc = 0.0\n",
    "\n",
    "#     accuracies = []\n",
    "#     losses = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print('-' * 10)\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         # Each epoch has a training and validation phase\n",
    "#         optimizer = lr_scheduler(optimizer, epoch)\n",
    "#         # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#         model.train()  # Set model to training mode\n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         running_total = 0\n",
    "\n",
    "#         counter=0\n",
    "#         # Iterate over data, getting one batch of inputs (images) and labels each time.\n",
    "#         for data in dset_loaders['train']:\n",
    "#             inputs, labels = data\n",
    "\n",
    "#             if use_gpu:\n",
    "#                 try:\n",
    "#                     inputs, labels = Variable(inputs.float().cuda()), Variable(labels.long().cuda())\n",
    "#                 except Exception as e:\n",
    "#                     print(\"ERROR! here are the inputs and labels before we print the full stack trace:\")\n",
    "#                     print(inputs, labels)\n",
    "#                     raise e\n",
    "#             else:\n",
    "#                 inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "#             # Set gradient to zero to delete history of computations in previous epoch. Track operations so that differentiation can be done automatically.\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "#             # outputs will be top 1 from softmax, labels will be single int\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Print a line every 10 batches so you have something to watch and don't feel like the program isn't running.\n",
    "#             if counter%10==0:\n",
    "#                 print(\"Reached batch iteration\", counter)\n",
    "\n",
    "#             counter+=1\n",
    "\n",
    "#             # backward + optimize only if in training phase\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             try:\n",
    "#                 running_loss += loss.item()\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "#                 running_total += len(labels.data)\n",
    "#             except:\n",
    "#                 print('unexpected error, could not calculate loss or do a sum.')\n",
    "\n",
    "#             epoch_loss = running_loss / 500\n",
    "#             epoch_acc = running_corrects.item() / running_total\n",
    "#             # print(running_corrects, running_total)\n",
    "#             print('{} Loss: {:.4f} Acc: {:.4f}'.format('training', epoch_loss, epoch_acc))\n",
    "#             accuracies.append(epoch_acc)\n",
    "#             losses.append(epoch_loss)\n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "#     print('returning and looping back')\n",
    "\n",
    "#     return best_model, accuracies, losses\n",
    "\n",
    "\n",
    "# This function changes the learning rate as the model trains.\n",
    "# If the learning rate is too high, training tends to be unstable and it's harder to converge on an optimal set of weights. \n",
    "# But, if learning rate is too low, learning is too slow and you won't converge in a reasonable time frame. A good compromise \n",
    "# is to start out with a high learning rate and then reduce it over time. \n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "def train_model(model, criterion, optimizer, lr_scheduler=None, num_epochs=100):\n",
    "    since = time.time()\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        # if lr_scheduler is not None:\n",
    "        #     optimizer = lr_scheduler(optimizer, epoch)\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for inputs, labels in dset_loaders['train']:\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            running_total += inputs.size(0)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        epoch_loss = running_loss / running_total\n",
    "        epoch_acc = running_corrects.double() / running_total\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format('Training', epoch_loss, epoch_acc))\n",
    "        accuracies.append(epoch_acc)\n",
    "        losses.append(epoch_loss)\n",
    "        best_acc = max(best_acc, epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return best_model, accuracies, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0134,  0.0159, -0.0116,  ...,  0.0188,  0.0180,  0.0075],\n",
      "        [ 0.0071,  0.0203,  0.0173,  ...,  0.0006, -0.0035,  0.0035],\n",
      "        [ 0.0004,  0.0120, -0.0180,  ...,  0.0098, -0.0098, -0.0211],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0042,  0.0006,  ...,  0.0147, -0.0020,  0.0013],\n",
      "        [ 0.0164, -0.0004, -0.0105,  ...,  0.0050,  0.0175,  0.0063],\n",
      "        [ 0.0101,  0.0048,  0.0193,  ...,  0.0019, -0.0212,  0.0124]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0211, -0.0115, -0.0007,  ..., -0.0037, -0.0208, -0.0005],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0006,  0.0111,  0.0024,  ..., -0.0185, -0.0194, -0.0177],\n",
      "        [-0.0242,  0.0236, -0.0098,  ...,  0.0050, -0.0192, -0.0056],\n",
      "        [ 0.0207,  0.0247, -0.0064,  ...,  0.0068,  0.0027, -0.0163],\n",
      "        ...,\n",
      "        [ 0.0099,  0.0238,  0.0191,  ...,  0.0022,  0.0080, -0.0174],\n",
      "        [ 0.0123, -0.0098,  0.0003,  ...,  0.0235, -0.0002, -0.0093],\n",
      "        [ 0.0245,  0.0076,  0.0073,  ..., -0.0075,  0.0059, -0.0118]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0227,  0.0134,  0.0059,  ...,  0.0103,  0.0146, -0.0242],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0070, -0.0025, -0.0094,  ..., -0.0178,  0.0132, -0.0131],\n",
      "        [ 0.0082,  0.0198,  0.0049,  ...,  0.0077, -0.0224,  0.0161],\n",
      "        [ 0.0121, -0.0143, -0.0022,  ..., -0.0029,  0.0049,  0.0083],\n",
      "        ...,\n",
      "        [-0.0215,  0.0216,  0.0192,  ..., -0.0022,  0.0117,  0.0120],\n",
      "        [-0.0081,  0.0112, -0.0170,  ...,  0.0189,  0.0226,  0.0085],\n",
      "        [ 0.0119, -0.0047,  0.0234,  ...,  0.0246,  0.0082, -0.0092]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-2.2487e-02,  1.0778e-02,  1.3859e-02,  1.8422e-02,  1.6401e-02,\n",
      "        -2.7858e-03, -3.7547e-03,  2.2921e-02,  1.1510e-02, -9.7219e-03,\n",
      "         4.2465e-03, -2.3117e-02, -2.2666e-02,  2.8231e-04, -1.3604e-02,\n",
      "         6.7424e-03,  1.5853e-02,  1.3296e-02,  1.9078e-02,  6.6843e-04,\n",
      "         3.7292e-04, -2.1615e-02,  1.0708e-02, -2.5051e-02,  1.2416e-02,\n",
      "        -9.7213e-03,  1.0159e-02, -1.1213e-02, -2.4397e-02, -2.2418e-02,\n",
      "         4.2482e-03, -1.1834e-02,  2.2173e-02, -2.3944e-02, -1.3757e-02,\n",
      "         1.4727e-02, -1.2990e-02,  1.3040e-02, -9.5726e-03, -1.1437e-02,\n",
      "         3.6831e-03,  8.2543e-03,  2.1564e-02,  2.9370e-03,  1.0990e-02,\n",
      "        -3.5944e-03, -1.6984e-02, -1.1006e-02, -1.4124e-02, -7.5491e-03,\n",
      "         8.2369e-03,  2.9665e-03,  6.5132e-03, -2.5732e-02, -1.4875e-02,\n",
      "         5.5851e-03, -2.3929e-02, -2.2887e-02, -2.0040e-02, -2.2865e-02,\n",
      "         2.5008e-02, -9.1694e-03,  2.1849e-02, -1.6773e-03, -1.5458e-02,\n",
      "         3.6544e-04,  1.3492e-02,  6.6619e-03,  4.5355e-03,  1.3309e-02,\n",
      "        -9.9500e-03,  1.0177e-02, -1.9473e-03, -1.8421e-02, -2.2734e-02,\n",
      "         1.6254e-02, -3.6968e-03,  1.2072e-02,  1.3834e-02,  8.3819e-08,\n",
      "         1.3437e-02,  9.3968e-04, -1.8675e-02, -1.5906e-02,  6.8212e-03,\n",
      "         6.0212e-03,  1.8153e-02, -9.8847e-04,  2.5351e-02,  2.0201e-02,\n",
      "        -1.0899e-02,  2.5447e-02, -2.1879e-02,  1.1414e-02,  1.1890e-02,\n",
      "         9.7051e-03, -2.5022e-02,  1.7963e-02,  2.5052e-03,  8.9439e-03,\n",
      "         2.2958e-02,  4.5564e-03,  2.1945e-03, -5.8965e-04,  1.3042e-02,\n",
      "        -2.0222e-02,  2.2912e-02,  1.6940e-02, -9.8102e-03,  1.5636e-02,\n",
      "        -1.3443e-03,  8.5235e-05, -8.2112e-03, -1.5440e-02, -4.0830e-03,\n",
      "         2.2909e-02,  9.6471e-03,  1.9210e-02, -5.1796e-03,  1.1046e-02,\n",
      "         1.4244e-02, -1.7279e-02, -6.9900e-03,  3.5866e-04, -1.5464e-04,\n",
      "        -1.1028e-02, -2.6999e-03,  8.0963e-03,  8.3646e-04, -1.0971e-02,\n",
      "         2.5652e-02,  1.5728e-02,  1.6579e-02, -1.7432e-02, -9.7609e-03,\n",
      "        -5.9735e-03, -1.7750e-02,  2.2499e-02,  2.3254e-02, -2.4262e-02,\n",
      "        -1.4682e-02, -1.8748e-02, -7.3500e-03, -6.9529e-03, -1.3743e-02,\n",
      "        -1.2412e-02, -2.0839e-02, -1.3102e-02,  1.3354e-04, -1.3227e-02,\n",
      "         1.4919e-02, -6.7467e-03, -1.5360e-02, -2.2073e-02,  1.0799e-02,\n",
      "        -7.1909e-03,  2.5025e-02,  2.4546e-02, -1.3132e-02,  2.3711e-02,\n",
      "         6.7950e-03,  2.0698e-02,  8.5546e-03,  3.3430e-03, -7.2647e-05,\n",
      "         1.5517e-02,  2.5585e-02,  3.9277e-03,  9.7009e-03, -1.7203e-02,\n",
      "         8.4460e-03,  5.0627e-03,  2.2521e-02,  9.8864e-03,  1.6215e-02,\n",
      "        -2.8361e-03, -1.7681e-02, -1.8609e-02,  1.4489e-02, -2.1189e-02,\n",
      "        -1.9814e-02,  1.3462e-02, -7.1669e-03, -7.6327e-03, -1.5886e-02,\n",
      "         1.6305e-02,  8.9003e-03,  1.5328e-02, -8.1425e-03,  2.4024e-02,\n",
      "        -8.2758e-03,  1.5873e-02, -6.0829e-03,  2.2975e-02, -2.3592e-02,\n",
      "         3.4968e-03,  2.4100e-02, -7.3976e-03,  2.5480e-02, -1.8101e-02,\n",
      "        -1.8596e-02, -1.2114e-02, -2.4025e-02,  7.4621e-03, -1.5986e-02,\n",
      "        -3.3847e-03,  1.9933e-02,  2.4951e-02, -1.6191e-02,  1.2331e-02,\n",
      "        -2.5115e-02, -5.4426e-06, -1.3987e-02,  9.2019e-03, -1.7520e-02,\n",
      "        -8.0754e-03, -6.1320e-03, -1.5960e-02, -2.1014e-02,  2.2674e-02,\n",
      "         3.3978e-04, -7.1410e-03, -9.1036e-03, -4.8143e-03,  1.9449e-02,\n",
      "        -2.4385e-02,  1.3399e-02,  2.3663e-02,  1.7520e-02, -1.8199e-02,\n",
      "         9.9962e-03,  1.3247e-02,  6.3470e-03,  1.0531e-02,  2.2044e-02,\n",
      "        -2.1363e-02,  3.6435e-03,  2.0488e-02, -1.5478e-02,  1.7072e-02,\n",
      "        -2.1358e-02,  3.2458e-03, -3.4698e-04, -9.9522e-03,  2.4946e-02,\n",
      "        -1.7488e-03, -1.3858e-02,  1.3103e-02, -1.0722e-02,  1.7296e-02,\n",
      "         8.5396e-03, -6.4084e-03, -8.1820e-03, -5.5028e-03,  1.7577e-02,\n",
      "        -2.1283e-02, -1.1658e-02,  6.7588e-03, -1.2318e-02, -9.0083e-03,\n",
      "         1.4674e-02, -2.5420e-02, -1.1853e-02,  1.7584e-02, -1.2324e-02,\n",
      "         8.3011e-03,  5.9535e-03,  6.2925e-03,  7.4146e-03, -1.8900e-02,\n",
      "        -2.1135e-02,  1.2362e-03, -6.1554e-03,  6.8728e-03, -6.2147e-03,\n",
      "        -3.5832e-04, -1.8484e-02,  3.0169e-03, -6.6317e-03, -2.3106e-02,\n",
      "        -1.8826e-02,  1.9494e-03,  1.4984e-03,  1.7353e-02, -2.4567e-02,\n",
      "        -2.6155e-03, -1.4095e-02, -1.0713e-02, -1.3784e-02, -4.1162e-03,\n",
      "        -1.2911e-02,  2.0103e-02,  3.0530e-03,  3.1002e-03, -1.8765e-02,\n",
      "         1.6598e-03,  1.8915e-02,  1.2821e-02, -2.5514e-03, -1.5404e-02,\n",
      "        -2.0401e-02,  8.4668e-03, -1.5306e-02, -5.9404e-03, -1.0123e-02,\n",
      "        -1.9159e-03, -1.0684e-02,  1.7798e-03,  4.7588e-03, -2.5223e-03,\n",
      "        -2.2466e-02,  2.4936e-02,  1.8294e-02, -2.1092e-02,  1.6367e-02,\n",
      "         2.2010e-02,  7.9342e-03, -2.0850e-02, -1.7115e-02, -4.2781e-04,\n",
      "         5.5774e-03,  8.5621e-03, -1.8509e-02,  1.0835e-02,  7.4070e-03,\n",
      "        -1.9185e-02, -9.7460e-03, -1.4934e-02, -2.2368e-02, -1.0888e-03,\n",
      "         1.2820e-02, -3.8033e-03, -8.2498e-04,  2.1556e-02, -5.2601e-03,\n",
      "         2.3763e-03,  6.1802e-04, -2.5366e-02, -2.4627e-02, -4.8151e-03,\n",
      "         2.1879e-02,  2.4496e-02,  2.2379e-02, -9.4484e-03, -2.9928e-03,\n",
      "         2.3725e-02, -1.7352e-02,  4.6400e-03,  2.4320e-02, -1.5220e-02,\n",
      "        -1.3554e-02, -2.3627e-02,  1.9489e-02,  1.0686e-02, -7.4846e-03,\n",
      "        -3.6359e-06, -5.8282e-03,  7.0881e-03,  5.5381e-03, -1.2970e-02,\n",
      "        -9.1786e-03, -5.4884e-03,  2.1176e-02,  2.2808e-02, -1.6390e-02,\n",
      "        -2.5133e-03, -4.2563e-03, -1.4444e-02,  1.0003e-02,  1.0892e-02,\n",
      "        -3.3797e-03,  1.9757e-02, -6.8859e-03,  1.4461e-02,  2.5600e-02,\n",
      "        -1.3860e-02, -9.4904e-03,  1.0613e-02, -1.1230e-02,  2.5523e-02,\n",
      "         1.8152e-02,  1.2470e-02, -2.4694e-03,  2.1571e-02,  2.3638e-02,\n",
      "        -4.5110e-03,  1.2415e-02, -2.2481e-03, -2.0938e-02, -1.4586e-02,\n",
      "        -1.8720e-02,  2.2731e-02,  1.8307e-02,  1.4067e-02, -2.4122e-02,\n",
      "         5.4230e-03, -2.8737e-03,  2.3233e-02, -2.3941e-02, -1.2380e-03,\n",
      "        -4.0018e-04,  1.2880e-02, -1.0097e-02, -7.1929e-03,  1.6895e-02,\n",
      "         1.1544e-02, -2.5415e-02, -2.4770e-02, -6.5524e-03, -1.8102e-02,\n",
      "         2.8846e-03, -1.4180e-02,  4.8071e-04, -2.9282e-03, -2.5539e-02,\n",
      "        -1.5456e-02, -2.3673e-02,  2.0035e-02, -8.4837e-03, -3.9261e-03,\n",
      "         1.2886e-02,  2.2172e-02,  1.5801e-02, -2.0248e-02,  2.5398e-02,\n",
      "        -1.0071e-02, -2.3450e-02, -1.7285e-02,  1.3571e-02,  1.0422e-02,\n",
      "        -1.3534e-02, -4.6699e-03,  1.5082e-02, -1.2588e-02,  1.0755e-02,\n",
      "        -6.0939e-03,  4.8288e-03,  1.2268e-02, -1.2581e-02,  4.5767e-03,\n",
      "         4.7780e-03,  2.3694e-02, -3.5945e-03,  3.4646e-03,  1.9790e-02,\n",
      "         6.6824e-04,  2.0987e-02, -1.3995e-02, -3.0086e-03, -8.7514e-03,\n",
      "         2.0325e-02, -2.4659e-02,  2.4578e-03, -6.7463e-04, -2.4737e-02,\n",
      "         1.4605e-02,  1.4468e-02, -4.2289e-03,  2.3715e-02, -1.2073e-02,\n",
      "        -2.0192e-02, -9.6095e-03,  1.1755e-02,  5.0486e-04,  7.0713e-03,\n",
      "        -9.2676e-04, -1.5006e-02, -9.3902e-03, -1.4590e-02,  1.2689e-02,\n",
      "        -3.6843e-03, -7.5639e-04,  2.3766e-02, -1.1245e-02, -3.9685e-04,\n",
      "        -7.9520e-03, -2.1166e-02,  2.0480e-02, -2.9401e-04, -9.3582e-03,\n",
      "        -5.2061e-03, -1.8928e-02, -6.1905e-04,  1.8165e-02,  7.0559e-03,\n",
      "         3.3024e-03,  1.5644e-02,  2.7134e-03, -1.5667e-02, -1.0918e-02,\n",
      "        -2.5142e-02, -2.3163e-02, -1.9405e-02, -1.6655e-02, -1.5164e-02,\n",
      "        -1.8815e-02,  1.9517e-02,  1.3443e-02, -1.4532e-02, -1.6419e-02],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "\n",
    "class ThreeLayerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ThreeLayerModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.softmax(x, dim=1)\n",
    "\n",
    "model_ft = ThreeLayerModel(1781, 1500, NUM_CLASSES)\n",
    "print(list(model_ft.parameters()))\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
    "# optimizer_ft = optim.RMSprop(model_ft.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = ExponentialLR(optimizer_ft, gamma=EPOCH_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeLayerModel(\n",
       "  (fc1): Linear(in_features=1781, out_features=1500, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=1500, out_features=1500, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=1500, out_features=500, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = ThreeLayerModel(1781, 1500, NUM_CLASSES)\n",
    "model_ft.load_state_dict(torch.load('small_unif.pt'))\n",
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5\n",
      "Training Loss: 6.2146 Acc: 0.0000\n",
      "Epoch 1/5\n",
      "Training Loss: 6.2144 Acc: 0.0160\n",
      "Epoch 2/5\n",
      "Training Loss: 6.2176 Acc: 0.0000\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the functions and save the best model in the function model_ft.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_ft, accuracies, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracies by epoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracies)\n",
      "Cell \u001b[0;32mIn[30], line 120\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, lr_scheduler, num_epochs)\u001b[0m\n\u001b[1;32m    117\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    118\u001b[0m running_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dset_loaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n\u001b[1;32m    122\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the functions and save the best model in the function model_ft.\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, scheduler, num_epochs=6)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    print(split, \"accuracies by epoch:\", accuracies)\n",
    "    print(split, \"losses by epoch:\", losses)\n",
    "\n",
    "# Save model\n",
    "torch.save(model_ft.state_dict(), '4_2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small model maxes out at 0.668 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
