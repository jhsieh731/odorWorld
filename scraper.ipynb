{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper for FlavorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captures only entities with full data, but it seems incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_res = requests.get('https://cosylab.iiitd.edu.in/flavordb/entities?entity=%20&category=')\n",
    "text_res = json.loads(json_res.text)\n",
    "res = json.loads(text_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all entities in `data.csv` (prelim, unused data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_records(res)\n",
    "data.to_csv('data.csv', index=False)\n",
    "\n",
    "with open('data.csv') as file:\n",
    "  csv_reader = csv.DictReader(file)\n",
    "  data = [row for row in csv_reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all available entity information into `data_chemicals.csv` (approx. 35 minutes on M1; USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n",
      "407\n",
      "414\n",
      "420\n"
     ]
    }
   ],
   "source": [
    "# molecules stored in indices from 0 to 978\n",
    "id = 0\n",
    "with open('data_chemicals.csv', 'a') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  # csv header\n",
    "  writer.writerow(['id', 'common_name', 'category', 'chemicals'])\n",
    "  while id <= 978:\n",
    "    try:\n",
    "      entity_res1 = requests.get(f'https://cosylab.iiitd.edu.in/flavordb/entities_json?id={id}')\n",
    "      entity_res = json.loads(entity_res1.text)\n",
    "      category = entity_res['category']\n",
    "      common_name = entity_res['entity_alias_readable']\n",
    "      # !! May want to grab functional groups here from entity_res['molecules'][i]['functional_groups']\n",
    "      molecules = list(map(lambda obj: obj['common_name'], entity_res['molecules']))\n",
    "      writer.writerow([id, common_name, category, str(molecules)])\n",
    "    except:\n",
    "      print(id)\n",
    "    finally:\n",
    "      id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing odor entities with identical chemical makeups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "data = []\n",
    "with open('data_chemicals.csv', 'r') as file:\n",
    "  csv_reader = csv.DictReader(file)\n",
    "  with open('data_final.csv', 'w') as write_file:\n",
    "    writer = csv.writer(write_file)\n",
    "    seen = set()\n",
    "    for row in csv_reader:\n",
    "      chemicals = row['chemicals']\n",
    "      # remove entities with duplicate chemical sets\n",
    "      if chemicals not in seen:\n",
    "        seen.add(chemicals)\n",
    "        writer.writerow(row.values())\n",
    "        # convert stringified list back into python list\n",
    "        data.append(ast.literal_eval(chemicals))\n",
    "\n",
    "# getting distinct chemicals\n",
    "chemical_set = set()\n",
    "for lst in data:\n",
    "  chemical_set.update(lst)\n",
    "\n",
    "print(len(chemical_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary encode `data_binary.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df = pd.read_csv('data_final.csv', names=['index', 'Name', 'type', 'chems'], header=None)\n",
    "df['chems'] = df['chems'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_set\n",
    "\n",
    "chemical_match = {chemical : i for i, chemical in enumerate(chemical_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x = {}\n",
    "binary_matrix = np.zeros((500, len(chemical_set)))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "  encoded_entity = np.zeros((len(chemical_set)))\n",
    "  chems = row['chems']\n",
    "  for item in chems:\n",
    "    encoded_entity[chemical_match[item]] = 1\n",
    "    binary_matrix[i][chemical_match[item]] = 1\n",
    "  x[df[\"index\"][i]] = encoded_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, pd.DataFrame(binary_matrix, columns=chemical_match)], axis=1).to_csv('data_binary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pickled inputs (500 x 1781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('binary_opens.pkl', 'wb') as writefile: \n",
    "  pkl.dump(x, writefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open('binary_opens.pkl', 'rb') as readfile:\n",
    "#   data = pkl.load(readfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dict.csv', 'w') as file:\n",
    "#   file.write('Name,Chemicals,Category\\n')\n",
    "#   keys = list(data.keys())\n",
    "#   for i in range(len(df)):\n",
    "#     idx = keys[i]\n",
    "#     if idx == df['index'][i]:\n",
    "#         file.write(f'{df[\"Name\"][i]},\"{str([i for i in data[idx]])}\",{df[\"type\"][i]}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
